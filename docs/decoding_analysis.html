<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.decoding_analysis API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.decoding_analysis</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from dataclasses import dataclass, field
import logging
from mne import epochs
from sklearn import svm

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support
from sklearn.pipeline import Pipeline, make_pipeline

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Tuple, Union
import seaborn as sns
import numpy as np
import mne
from sklearn.utils import multiclass


@dataclass
class Classifier(ABC):
    &#34;&#34;&#34;Base classifier&#34;&#34;&#34;

    @abstractmethod
    def fit():
        pass

    @abstractmethod
    def predict() -&gt; np.ndarray:
        pass


@dataclass
class LDADecoder(Classifier):
    &#34;&#34;&#34;Simple sklearn LDA decoder&#34;&#34;&#34;
    lda: LinearDiscriminantAnalysis = field(
        init=False, default_factory=LinearDiscriminantAnalysis)

    def fit(self, data: np.ndarray, labels: np.ndarray) -&gt; None:
        data = data.reshape(data.shape[0], -1)
        self.lda.fit(data, labels)

    def predict(self, data: np.ndarray, labels: np.ndarray) -&gt; float:
        score = self.lda.score(data, labels)
        logging.info(&#34;Score {}&#34;.format(score))
        return score


@dataclass
class CVPipleline(Classifier):
    &#34;&#34;&#34;Cross-validation pipleline&#34;&#34;&#34;
    cv_pip: Pipeline
    train_data: np.ndarray
    test_data: np.ndarray
    train_labels: np.ndarray
    test_labels: np.ndarray

    def fit(self, **kwargs):
        self.cv_pip.fit(self.train_data, self.train_labels, **kwargs)

    def predict(self, **kwargs) -&gt; np.ndarray:
        self.predictions = self.cv_pip.predict(self.test_data, **kwargs)

    def evaluate(self, target_names: list[str] = [&#39;Rare&#39;, &#39;Frequent&#39;]):
        report = classification_report(self.test_labels,
                                       self.predictions,
                                       target_names=target_names)
        print(&#39;Clasification Report:\n {}&#39;.format(report))

        acc = accuracy_score(self.test_labels, self.predictions)
        print(&#34;Accuracy of model: {}&#34;.format(acc))

        precision, recall, fscore, support = precision_recall_fscore_support(
            self.test_labels, self.predictions, average=&#39;macro&#39;)
        print(&#39;Precision: {0}, Recall: {1}, f1-score:{2}&#39;.format(
            precision, recall, fscore))
        return acc, fscore


@dataclass
class CrossTimePipelineDecoder(Classifier):
    &#34;&#34;&#34;Classifier across time
    Taken from EEG: excercise (https://github.com/s-ccs/course_eeg_SS2021/tree/main/exercises)
    &#34;&#34;&#34;
    pipeline: Pipeline
    X: np.ndarray = field(init=False, repr=False)
    y: np.ndarray = field(init=False, repr=False)
    epochs: mne.Epochs = field(init=False, repr=False)
    timeVec: np.ndarray = field(init=False, repr=False)
    t_scores: List[float] = field(init=False, default_factory=list, repr=False)

    def fit(self,
            epochs: mne.Epochs,
            labels: np.ndarray,
            resampling_freq: float = 40) -&gt; None:
        self.epochs = epochs.load_data().resample(resampling_freq)
        self.X = self.epochs.get_data()
        self.y = labels
        self.timeVec = epochs.times

    def predict(self, w_size: float) -&gt; np.array:
        timeVec = self.timeVec[::10]
        for t, w_time in enumerate(timeVec):
            w_tmin = w_time - w_size / 2.
            w_tmax = w_time + w_size / 2.

            # stop the program if the timewindow is outside of our epoch
            if w_tmin &lt; timeVec[0]:
                continue
            if w_tmax &gt; timeVec[len(timeVec) - 1]:
                continue
            # Crop data into time-window of interest
            X = self.epochs.crop(w_tmin, w_tmax).get_data()

            # Save mean scores over folds for each frequency and time window
            self.t_scores.append(
                np.mean(cross_val_score(estimator=self.pipeline,
                                        X=X,
                                        y=self.y,
                                        scoring=&#39;roc_auc&#39;,
                                        cv=2,
                                        n_jobs=2),
                        axis=0))
        return np.array(self.t_scores)


@dataclass
class FeatureTransformer(ABC):
    &#34;&#34;&#34;Base Transformer&#34;&#34;&#34;

    @abstractmethod
    def transform() -&gt; np.ndarray:
        pass


@dataclass
class MNECSPTransformer(FeatureTransformer):
    &#34;&#34;&#34;Simple CSP built on top of MNE&#34;&#34;&#34;
    n_components: int

    def transform(self, data: np.ndarray, labels: np.ndarray) -&gt; np.ndarray:
        csp = mne.decoding.CSP(self.n_components)
        csp.fit_transform(data, labels)
        return csp.transform(data)


@dataclass
class EEGDecoder():
    &#34;&#34;&#34;Decode EEG data using condition, epochs&#34;&#34;&#34;
    condition: Union[str, List[str]]
    epoch_times: Tuple[float, float]
    decoding_times: Tuple[float, float]
    raw: mne.io.Raw = field(repr=False)
    equalize_events: bool = False
    baseline: Union[Tuple, None] = None
    reject_by_annotation: bool = False
    reject: Union[dict, None] = None
    epochs: mne.Epochs = field(init=False, repr=False)
    score: np.ndarray = field(init=False, repr=False)
    equalize_ids: list[str] = field(default_factory=list)

    def __post_init__(self):
        events, ids = mne.events_from_annotations(self.raw)
        epochs = mne.Epochs(self.raw,
                            events,
                            ids,
                            self.epoch_times[0],
                            self.epoch_times[1],
                            self.baseline,
                            reject_by_annotation=self.reject_by_annotation,
                            reject=self.reject,
                            picks=[&#39;eeg&#39;])
        if self.equalize_events:
            if len(self.equalize_ids) &gt; 0:
                epochs.equalize_event_counts(self.equalize_ids)
            else:
                epochs.equalize_event_counts(ids)
        self.epochs = epochs[self.condition].load_data().crop(
            self.decoding_times[0], self.decoding_times[1])

    def _equalize_samples(self, data: np.ndarray,
                          labels: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Helper funciton to equalize the data and labels&#34;&#34;&#34;
        labels_freq = np.random.choice(
            np.where(labels == 2)[0], len(np.where(labels == 1)[0]))
        labels_rare = np.where(labels == 1)[0]
        labels_idx = np.hstack((labels_freq, labels_rare))

        data = data[labels_idx, :]
        labels = labels[labels_idx]

        return data, labels

    def get_train(
            self,
            channels: list[str] = None,
            transform_feature: bool = False,
            equalize_labels_count: bool = False
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Returns training data from the epochs averaged across times&#34;&#34;&#34;
        if channels:
            data = np.array(self.epochs.get_data(picks=channels))
        else:
            data = np.array(self.epochs.get_data())

        if transform_feature:
            data, labels = self.feature_transform(data), self.labels_transform()
        else:
            data, labels = data, self.labels_transform()

        if equalize_labels_count:
            data, labels = self._equalize_samples(data, labels)

        return data, labels

    def get_all_stim(self,
                     equalize_labels_count: bool = False) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Returns dictionary of epochs, data, labels, and balanced training data&#34;&#34;&#34;

        epoch_A = self.epochs[&#39;stimulus/A&#39;].copy()
        epoch_B = self.epochs[&#39;stimulus/B&#39;].copy()
        epoch_C = self.epochs[&#39;stimulus/C&#39;].copy()
        epoch_D = self.epochs[&#39;stimulus/D&#39;].copy()
        epoch_E = self.epochs[&#39;stimulus/E&#39;].copy()

        data = {
            &#39;A&#39;: {
                &#39;epoch&#39;:
                    epoch_A,
                &#39;data&#39;:
                    epoch_A.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_A),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_A.get_data().mean(axis=2),
                                           self.labels_transform(epoch_A))
            },
            &#39;B&#39;: {
                &#39;epoch&#39;:
                    epoch_B,
                &#39;data&#39;:
                    epoch_B.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_B),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_B.get_data().mean(axis=2),
                                           self.labels_transform(epoch_B))
            },
            &#39;C&#39;: {
                &#39;epoch&#39;:
                    epoch_C,
                &#39;data&#39;:
                    epoch_C.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_C),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_C.get_data().mean(axis=2),
                                           self.labels_transform(epoch_C))
            },
            &#39;D&#39;: {
                &#39;epoch&#39;:
                    epoch_D,
                &#39;data&#39;:
                    epoch_D.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_D),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_D.get_data().mean(axis=2),
                                           self.labels_transform(epoch_D))
            },
            &#39;E&#39;: {
                &#39;epoch&#39;:
                    epoch_E,
                &#39;data&#39;:
                    epoch_E.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_E),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_E.get_data().mean(axis=2),
                                           self.labels_transform(epoch_E))
            },
        }

        return data

    def feature_transform(
        self, transformer: FeatureTransformer = MNECSPTransformer(2)
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Transform data using custom Transformers&#34;&#34;&#34;
        labels = self.labels_transform()
        data = transformer.transform(self.epochs.get_data(), labels)
        return data, labels

    def labels_transform(self,
                         epochs: mne.Epochs = None,
                         n_classes: int = 2) -&gt; np.ndarray:
        &#34;&#34;&#34;Returns class labels from the epochs events based on number of classes&#34;&#34;&#34;
        _epochs = epochs if epochs else self.epochs
        _labels = epochs.events[:, -1] if epochs else self.epochs.events[:, -1]
        _, rare, _ = P3.EVENTS_MAPINGS()
        wanted_keys = [
            _epochs.event_id[key]
            for key in _epochs.event_id
            if int(key.split(&#39;/&#39;)[-1]) in rare
        ]
        rare_stims = np.array([_epochs.events[key] for key in wanted_keys])
        rare_stims = rare_stims[:, -1]
        labels = np.where(np.isin(_labels, rare_stims), 1, 2)
        return labels

    def run_svm_(self) -&gt; Tuple[object, object]:
        &#34;&#34;&#34;Runs inside a seperate process using multiprocessing&#34;&#34;&#34;
        from mne.decoding.transformer import Vectorizer
        from sklearn.preprocessing import StandardScaler
        from sklearn import svm
        from sklearn.model_selection import GridSearchCV, StratifiedKFold
        data, labels = self.get_train(channels=[&#39;Cz&#39;, &#39;CPz&#39;])
        clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(),
                                    svm.SVC(random_state=42))
        parameters = {
            &#39;svc__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;sigmoid&#39;],
            &#39;svc__C&#39;: [0.1, 1, 10]
        }
        gs_cv_svm = GridSearchCV(clf_svm_pip,
                                 parameters,
                                 scoring=&#39;accuracy&#39;,
                                 cv=StratifiedKFold(n_splits=5),
                                 return_train_score=True)
        gs_cv_svm.fit(data, labels)
        logging.info(&#39;Best Parameters: {}&#39;.format(gs_cv_svm.best_params_))
        logging.info(&#39;Best Score: {}&#39;.format(gs_cv_svm.best_score_))
        return gs_cv_svm.best_score_, gs_cv_svm.best_params_

    def run_sliding_(self) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Runs inside a seperate process using multiprocessing&#34;&#34;&#34;
        from mne.decoding.search_light import SlidingEstimator
        from mne.decoding.transformer import Vectorizer
        from sklearn.preprocessing import StandardScaler
        from sklearn.model_selection import StratifiedKFold
        from mne.decoding.base import cross_val_multiscore

        clf_svm = make_pipeline(Vectorizer(), StandardScaler(),
                                svm.SVC(kernel=&#39;linear&#39;, C=1))
        timeDecode = SlidingEstimator(clf_svm, scoring=&#39;roc_auc&#39;, n_jobs=3)
        epochs = self.epochs.load_data()
        labels = self.labels_transform()
        scores = cross_val_multiscore(timeDecode,
                                      epochs.get_data(),
                                      labels,
                                      cv=StratifiedKFold(5, True, 114),
                                      n_jobs=6)
        return (epochs.times, scores)


class P3:

    @abstractmethod
    def EVENTS_MAPINGS() -&gt; Tuple[dict, list[int], list[int]]:
        &#34;&#34;&#34;Returns events mapping for the P3 task&#34;&#34;&#34;
        blocks = np.array(
            [list(range(10 * x + 1, 10 * x + 6)) for x in range(1, 6)])
        rare = np.array([x + i for i, x in enumerate(range(11, 56, 10))
                        ]).tolist()
        freq = np.setdiff1d(blocks.flatten(), rare).tolist()

        stimlus = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;]

        evts_stim = [
            &#39;stimulus/&#39; + stimlus[i] + &#39;/&#39; + str(alph)
            for i, x in enumerate(blocks)
            for alph in x
        ]
        evts_id = dict((i + 3, evts_stim[i]) for i in range(0, len(evts_stim)))
        evts_id[1] = &#39;response/201&#39;
        evts_id[2] = &#39;response/202&#39;
        return evts_id, rare, freq</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.decoding_analysis.CVPipleline"><code class="flex name class">
<span>class <span class="ident">CVPipleline</span></span>
<span>(</span><span>cv_pip: sklearn.pipeline.Pipeline, train_data: numpy.ndarray, test_data: numpy.ndarray, train_labels: numpy.ndarray, test_labels: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Cross-validation pipleline</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class CVPipleline(Classifier):
    &#34;&#34;&#34;Cross-validation pipleline&#34;&#34;&#34;
    cv_pip: Pipeline
    train_data: np.ndarray
    test_data: np.ndarray
    train_labels: np.ndarray
    test_labels: np.ndarray

    def fit(self, **kwargs):
        self.cv_pip.fit(self.train_data, self.train_labels, **kwargs)

    def predict(self, **kwargs) -&gt; np.ndarray:
        self.predictions = self.cv_pip.predict(self.test_data, **kwargs)

    def evaluate(self, target_names: list[str] = [&#39;Rare&#39;, &#39;Frequent&#39;]):
        report = classification_report(self.test_labels,
                                       self.predictions,
                                       target_names=target_names)
        print(&#39;Clasification Report:\n {}&#39;.format(report))

        acc = accuracy_score(self.test_labels, self.predictions)
        print(&#34;Accuracy of model: {}&#34;.format(acc))

        precision, recall, fscore, support = precision_recall_fscore_support(
            self.test_labels, self.predictions, average=&#39;macro&#39;)
        print(&#39;Precision: {0}, Recall: {1}, f1-score:{2}&#39;.format(
            precision, recall, fscore))
        return acc, fscore</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.decoding_analysis.Classifier" href="#src.decoding_analysis.Classifier">Classifier</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.decoding_analysis.CVPipleline.cv_pip"><code class="name">var <span class="ident">cv_pip</span> : sklearn.pipeline.Pipeline</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CVPipleline.test_data"><code class="name">var <span class="ident">test_data</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CVPipleline.test_labels"><code class="name">var <span class="ident">test_labels</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CVPipleline.train_data"><code class="name">var <span class="ident">train_data</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CVPipleline.train_labels"><code class="name">var <span class="ident">train_labels</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.CVPipleline.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, target_names: list = ['Rare', 'Frequent'])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, target_names: list[str] = [&#39;Rare&#39;, &#39;Frequent&#39;]):
    report = classification_report(self.test_labels,
                                   self.predictions,
                                   target_names=target_names)
    print(&#39;Clasification Report:\n {}&#39;.format(report))

    acc = accuracy_score(self.test_labels, self.predictions)
    print(&#34;Accuracy of model: {}&#34;.format(acc))

    precision, recall, fscore, support = precision_recall_fscore_support(
        self.test_labels, self.predictions, average=&#39;macro&#39;)
    print(&#39;Precision: {0}, Recall: {1}, f1-score:{2}&#39;.format(
        precision, recall, fscore))
    return acc, fscore</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.CVPipleline.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, **kwargs):
    self.cv_pip.fit(self.train_data, self.train_labels, **kwargs)</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.CVPipleline.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, **kwargs) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, **kwargs) -&gt; np.ndarray:
    self.predictions = self.cv_pip.predict(self.test_data, **kwargs)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.Classifier"><code class="flex name class">
<span>class <span class="ident">Classifier</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base classifier</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class Classifier(ABC):
    &#34;&#34;&#34;Base classifier&#34;&#34;&#34;

    @abstractmethod
    def fit():
        pass

    @abstractmethod
    def predict() -&gt; np.ndarray:
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="src.decoding_analysis.CVPipleline" href="#src.decoding_analysis.CVPipleline">CVPipleline</a></li>
<li><a title="src.decoding_analysis.CrossTimePipelineDecoder" href="#src.decoding_analysis.CrossTimePipelineDecoder">CrossTimePipelineDecoder</a></li>
<li><a title="src.decoding_analysis.LDADecoder" href="#src.decoding_analysis.LDADecoder">LDADecoder</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.Classifier.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def fit():
    pass</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.Classifier.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def predict() -&gt; np.ndarray:
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder"><code class="flex name class">
<span>class <span class="ident">CrossTimePipelineDecoder</span></span>
<span>(</span><span>pipeline: sklearn.pipeline.Pipeline)</span>
</code></dt>
<dd>
<div class="desc"><p>Classifier across time
Taken from EEG: excercise (<a href="https://github.com/s-ccs/course_eeg_SS2021/tree/main/exercises">https://github.com/s-ccs/course_eeg_SS2021/tree/main/exercises</a>)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class CrossTimePipelineDecoder(Classifier):
    &#34;&#34;&#34;Classifier across time
    Taken from EEG: excercise (https://github.com/s-ccs/course_eeg_SS2021/tree/main/exercises)
    &#34;&#34;&#34;
    pipeline: Pipeline
    X: np.ndarray = field(init=False, repr=False)
    y: np.ndarray = field(init=False, repr=False)
    epochs: mne.Epochs = field(init=False, repr=False)
    timeVec: np.ndarray = field(init=False, repr=False)
    t_scores: List[float] = field(init=False, default_factory=list, repr=False)

    def fit(self,
            epochs: mne.Epochs,
            labels: np.ndarray,
            resampling_freq: float = 40) -&gt; None:
        self.epochs = epochs.load_data().resample(resampling_freq)
        self.X = self.epochs.get_data()
        self.y = labels
        self.timeVec = epochs.times

    def predict(self, w_size: float) -&gt; np.array:
        timeVec = self.timeVec[::10]
        for t, w_time in enumerate(timeVec):
            w_tmin = w_time - w_size / 2.
            w_tmax = w_time + w_size / 2.

            # stop the program if the timewindow is outside of our epoch
            if w_tmin &lt; timeVec[0]:
                continue
            if w_tmax &gt; timeVec[len(timeVec) - 1]:
                continue
            # Crop data into time-window of interest
            X = self.epochs.crop(w_tmin, w_tmax).get_data()

            # Save mean scores over folds for each frequency and time window
            self.t_scores.append(
                np.mean(cross_val_score(estimator=self.pipeline,
                                        X=X,
                                        y=self.y,
                                        scoring=&#39;roc_auc&#39;,
                                        cv=2,
                                        n_jobs=2),
                        axis=0))
        return np.array(self.t_scores)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.decoding_analysis.Classifier" href="#src.decoding_analysis.Classifier">Classifier</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.X"><code class="name">var <span class="ident">X</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.epochs"><code class="name">var <span class="ident">epochs</span> : mne.epochs.Epochs</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.pipeline"><code class="name">var <span class="ident">pipeline</span> : sklearn.pipeline.Pipeline</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.t_scores"><code class="name">var <span class="ident">t_scores</span> : List[float]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.timeVec"><code class="name">var <span class="ident">timeVec</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.y"><code class="name">var <span class="ident">y</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, epochs: mne.epochs.Epochs, labels: numpy.ndarray, resampling_freq: float = 40) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self,
        epochs: mne.Epochs,
        labels: np.ndarray,
        resampling_freq: float = 40) -&gt; None:
    self.epochs = epochs.load_data().resample(resampling_freq)
    self.X = self.epochs.get_data()
    self.y = labels
    self.timeVec = epochs.times</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.CrossTimePipelineDecoder.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, w_size: float) ‑> <built-in function array></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, w_size: float) -&gt; np.array:
    timeVec = self.timeVec[::10]
    for t, w_time in enumerate(timeVec):
        w_tmin = w_time - w_size / 2.
        w_tmax = w_time + w_size / 2.

        # stop the program if the timewindow is outside of our epoch
        if w_tmin &lt; timeVec[0]:
            continue
        if w_tmax &gt; timeVec[len(timeVec) - 1]:
            continue
        # Crop data into time-window of interest
        X = self.epochs.crop(w_tmin, w_tmax).get_data()

        # Save mean scores over folds for each frequency and time window
        self.t_scores.append(
            np.mean(cross_val_score(estimator=self.pipeline,
                                    X=X,
                                    y=self.y,
                                    scoring=&#39;roc_auc&#39;,
                                    cv=2,
                                    n_jobs=2),
                    axis=0))
    return np.array(self.t_scores)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.EEGDecoder"><code class="flex name class">
<span>class <span class="ident">EEGDecoder</span></span>
<span>(</span><span>condition: Union[str, List[str]], epoch_times: Tuple[float, float], decoding_times: Tuple[float, float], raw: mne.io.fiff.raw.Raw, equalize_events: bool = False, baseline: Optional[Tuple] = None, reject_by_annotation: bool = False, reject: Optional[dict] = None, equalize_ids: list = &lt;factory&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Decode EEG data using condition, epochs</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class EEGDecoder():
    &#34;&#34;&#34;Decode EEG data using condition, epochs&#34;&#34;&#34;
    condition: Union[str, List[str]]
    epoch_times: Tuple[float, float]
    decoding_times: Tuple[float, float]
    raw: mne.io.Raw = field(repr=False)
    equalize_events: bool = False
    baseline: Union[Tuple, None] = None
    reject_by_annotation: bool = False
    reject: Union[dict, None] = None
    epochs: mne.Epochs = field(init=False, repr=False)
    score: np.ndarray = field(init=False, repr=False)
    equalize_ids: list[str] = field(default_factory=list)

    def __post_init__(self):
        events, ids = mne.events_from_annotations(self.raw)
        epochs = mne.Epochs(self.raw,
                            events,
                            ids,
                            self.epoch_times[0],
                            self.epoch_times[1],
                            self.baseline,
                            reject_by_annotation=self.reject_by_annotation,
                            reject=self.reject,
                            picks=[&#39;eeg&#39;])
        if self.equalize_events:
            if len(self.equalize_ids) &gt; 0:
                epochs.equalize_event_counts(self.equalize_ids)
            else:
                epochs.equalize_event_counts(ids)
        self.epochs = epochs[self.condition].load_data().crop(
            self.decoding_times[0], self.decoding_times[1])

    def _equalize_samples(self, data: np.ndarray,
                          labels: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Helper funciton to equalize the data and labels&#34;&#34;&#34;
        labels_freq = np.random.choice(
            np.where(labels == 2)[0], len(np.where(labels == 1)[0]))
        labels_rare = np.where(labels == 1)[0]
        labels_idx = np.hstack((labels_freq, labels_rare))

        data = data[labels_idx, :]
        labels = labels[labels_idx]

        return data, labels

    def get_train(
            self,
            channels: list[str] = None,
            transform_feature: bool = False,
            equalize_labels_count: bool = False
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Returns training data from the epochs averaged across times&#34;&#34;&#34;
        if channels:
            data = np.array(self.epochs.get_data(picks=channels))
        else:
            data = np.array(self.epochs.get_data())

        if transform_feature:
            data, labels = self.feature_transform(data), self.labels_transform()
        else:
            data, labels = data, self.labels_transform()

        if equalize_labels_count:
            data, labels = self._equalize_samples(data, labels)

        return data, labels

    def get_all_stim(self,
                     equalize_labels_count: bool = False) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Returns dictionary of epochs, data, labels, and balanced training data&#34;&#34;&#34;

        epoch_A = self.epochs[&#39;stimulus/A&#39;].copy()
        epoch_B = self.epochs[&#39;stimulus/B&#39;].copy()
        epoch_C = self.epochs[&#39;stimulus/C&#39;].copy()
        epoch_D = self.epochs[&#39;stimulus/D&#39;].copy()
        epoch_E = self.epochs[&#39;stimulus/E&#39;].copy()

        data = {
            &#39;A&#39;: {
                &#39;epoch&#39;:
                    epoch_A,
                &#39;data&#39;:
                    epoch_A.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_A),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_A.get_data().mean(axis=2),
                                           self.labels_transform(epoch_A))
            },
            &#39;B&#39;: {
                &#39;epoch&#39;:
                    epoch_B,
                &#39;data&#39;:
                    epoch_B.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_B),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_B.get_data().mean(axis=2),
                                           self.labels_transform(epoch_B))
            },
            &#39;C&#39;: {
                &#39;epoch&#39;:
                    epoch_C,
                &#39;data&#39;:
                    epoch_C.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_C),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_C.get_data().mean(axis=2),
                                           self.labels_transform(epoch_C))
            },
            &#39;D&#39;: {
                &#39;epoch&#39;:
                    epoch_D,
                &#39;data&#39;:
                    epoch_D.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_D),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_D.get_data().mean(axis=2),
                                           self.labels_transform(epoch_D))
            },
            &#39;E&#39;: {
                &#39;epoch&#39;:
                    epoch_E,
                &#39;data&#39;:
                    epoch_E.get_data(),
                &#39;labels&#39;:
                    self.labels_transform(epoch_E),
                &#39;norm_samples&#39;:
                    self._equalize_samples(epoch_E.get_data().mean(axis=2),
                                           self.labels_transform(epoch_E))
            },
        }

        return data

    def feature_transform(
        self, transformer: FeatureTransformer = MNECSPTransformer(2)
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Transform data using custom Transformers&#34;&#34;&#34;
        labels = self.labels_transform()
        data = transformer.transform(self.epochs.get_data(), labels)
        return data, labels

    def labels_transform(self,
                         epochs: mne.Epochs = None,
                         n_classes: int = 2) -&gt; np.ndarray:
        &#34;&#34;&#34;Returns class labels from the epochs events based on number of classes&#34;&#34;&#34;
        _epochs = epochs if epochs else self.epochs
        _labels = epochs.events[:, -1] if epochs else self.epochs.events[:, -1]
        _, rare, _ = P3.EVENTS_MAPINGS()
        wanted_keys = [
            _epochs.event_id[key]
            for key in _epochs.event_id
            if int(key.split(&#39;/&#39;)[-1]) in rare
        ]
        rare_stims = np.array([_epochs.events[key] for key in wanted_keys])
        rare_stims = rare_stims[:, -1]
        labels = np.where(np.isin(_labels, rare_stims), 1, 2)
        return labels

    def run_svm_(self) -&gt; Tuple[object, object]:
        &#34;&#34;&#34;Runs inside a seperate process using multiprocessing&#34;&#34;&#34;
        from mne.decoding.transformer import Vectorizer
        from sklearn.preprocessing import StandardScaler
        from sklearn import svm
        from sklearn.model_selection import GridSearchCV, StratifiedKFold
        data, labels = self.get_train(channels=[&#39;Cz&#39;, &#39;CPz&#39;])
        clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(),
                                    svm.SVC(random_state=42))
        parameters = {
            &#39;svc__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;sigmoid&#39;],
            &#39;svc__C&#39;: [0.1, 1, 10]
        }
        gs_cv_svm = GridSearchCV(clf_svm_pip,
                                 parameters,
                                 scoring=&#39;accuracy&#39;,
                                 cv=StratifiedKFold(n_splits=5),
                                 return_train_score=True)
        gs_cv_svm.fit(data, labels)
        logging.info(&#39;Best Parameters: {}&#39;.format(gs_cv_svm.best_params_))
        logging.info(&#39;Best Score: {}&#39;.format(gs_cv_svm.best_score_))
        return gs_cv_svm.best_score_, gs_cv_svm.best_params_

    def run_sliding_(self) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;Runs inside a seperate process using multiprocessing&#34;&#34;&#34;
        from mne.decoding.search_light import SlidingEstimator
        from mne.decoding.transformer import Vectorizer
        from sklearn.preprocessing import StandardScaler
        from sklearn.model_selection import StratifiedKFold
        from mne.decoding.base import cross_val_multiscore

        clf_svm = make_pipeline(Vectorizer(), StandardScaler(),
                                svm.SVC(kernel=&#39;linear&#39;, C=1))
        timeDecode = SlidingEstimator(clf_svm, scoring=&#39;roc_auc&#39;, n_jobs=3)
        epochs = self.epochs.load_data()
        labels = self.labels_transform()
        scores = cross_val_multiscore(timeDecode,
                                      epochs.get_data(),
                                      labels,
                                      cv=StratifiedKFold(5, True, 114),
                                      n_jobs=6)
        return (epochs.times, scores)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.decoding_analysis.EEGDecoder.baseline"><code class="name">var <span class="ident">baseline</span> : Optional[Tuple]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.condition"><code class="name">var <span class="ident">condition</span> : Union[str, List[str]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.decoding_times"><code class="name">var <span class="ident">decoding_times</span> : Tuple[float, float]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.epoch_times"><code class="name">var <span class="ident">epoch_times</span> : Tuple[float, float]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.epochs"><code class="name">var <span class="ident">epochs</span> : mne.epochs.Epochs</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.equalize_events"><code class="name">var <span class="ident">equalize_events</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.equalize_ids"><code class="name">var <span class="ident">equalize_ids</span> : list</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.raw"><code class="name">var <span class="ident">raw</span> : mne.io.fiff.raw.Raw</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.reject"><code class="name">var <span class="ident">reject</span> : Optional[dict]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.reject_by_annotation"><code class="name">var <span class="ident">reject_by_annotation</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.score"><code class="name">var <span class="ident">score</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.EEGDecoder.feature_transform"><code class="name flex">
<span>def <span class="ident">feature_transform</span></span>(<span>self, transformer: <a title="src.decoding_analysis.FeatureTransformer" href="#src.decoding_analysis.FeatureTransformer">FeatureTransformer</a> = MNECSPTransformer(n_components=2)) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Transform data using custom Transformers</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def feature_transform(
    self, transformer: FeatureTransformer = MNECSPTransformer(2)
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Transform data using custom Transformers&#34;&#34;&#34;
    labels = self.labels_transform()
    data = transformer.transform(self.epochs.get_data(), labels)
    return data, labels</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.get_all_stim"><code class="name flex">
<span>def <span class="ident">get_all_stim</span></span>(<span>self, equalize_labels_count: bool = False) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns dictionary of epochs, data, labels, and balanced training data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_stim(self,
                 equalize_labels_count: bool = False) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Returns dictionary of epochs, data, labels, and balanced training data&#34;&#34;&#34;

    epoch_A = self.epochs[&#39;stimulus/A&#39;].copy()
    epoch_B = self.epochs[&#39;stimulus/B&#39;].copy()
    epoch_C = self.epochs[&#39;stimulus/C&#39;].copy()
    epoch_D = self.epochs[&#39;stimulus/D&#39;].copy()
    epoch_E = self.epochs[&#39;stimulus/E&#39;].copy()

    data = {
        &#39;A&#39;: {
            &#39;epoch&#39;:
                epoch_A,
            &#39;data&#39;:
                epoch_A.get_data(),
            &#39;labels&#39;:
                self.labels_transform(epoch_A),
            &#39;norm_samples&#39;:
                self._equalize_samples(epoch_A.get_data().mean(axis=2),
                                       self.labels_transform(epoch_A))
        },
        &#39;B&#39;: {
            &#39;epoch&#39;:
                epoch_B,
            &#39;data&#39;:
                epoch_B.get_data(),
            &#39;labels&#39;:
                self.labels_transform(epoch_B),
            &#39;norm_samples&#39;:
                self._equalize_samples(epoch_B.get_data().mean(axis=2),
                                       self.labels_transform(epoch_B))
        },
        &#39;C&#39;: {
            &#39;epoch&#39;:
                epoch_C,
            &#39;data&#39;:
                epoch_C.get_data(),
            &#39;labels&#39;:
                self.labels_transform(epoch_C),
            &#39;norm_samples&#39;:
                self._equalize_samples(epoch_C.get_data().mean(axis=2),
                                       self.labels_transform(epoch_C))
        },
        &#39;D&#39;: {
            &#39;epoch&#39;:
                epoch_D,
            &#39;data&#39;:
                epoch_D.get_data(),
            &#39;labels&#39;:
                self.labels_transform(epoch_D),
            &#39;norm_samples&#39;:
                self._equalize_samples(epoch_D.get_data().mean(axis=2),
                                       self.labels_transform(epoch_D))
        },
        &#39;E&#39;: {
            &#39;epoch&#39;:
                epoch_E,
            &#39;data&#39;:
                epoch_E.get_data(),
            &#39;labels&#39;:
                self.labels_transform(epoch_E),
            &#39;norm_samples&#39;:
                self._equalize_samples(epoch_E.get_data().mean(axis=2),
                                       self.labels_transform(epoch_E))
        },
    }

    return data</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.get_train"><code class="name flex">
<span>def <span class="ident">get_train</span></span>(<span>self, channels: list = None, transform_feature: bool = False, equalize_labels_count: bool = False) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns training data from the epochs averaged across times</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_train(
        self,
        channels: list[str] = None,
        transform_feature: bool = False,
        equalize_labels_count: bool = False
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Returns training data from the epochs averaged across times&#34;&#34;&#34;
    if channels:
        data = np.array(self.epochs.get_data(picks=channels))
    else:
        data = np.array(self.epochs.get_data())

    if transform_feature:
        data, labels = self.feature_transform(data), self.labels_transform()
    else:
        data, labels = data, self.labels_transform()

    if equalize_labels_count:
        data, labels = self._equalize_samples(data, labels)

    return data, labels</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.labels_transform"><code class="name flex">
<span>def <span class="ident">labels_transform</span></span>(<span>self, epochs: mne.epochs.Epochs = None, n_classes: int = 2) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Returns class labels from the epochs events based on number of classes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def labels_transform(self,
                     epochs: mne.Epochs = None,
                     n_classes: int = 2) -&gt; np.ndarray:
    &#34;&#34;&#34;Returns class labels from the epochs events based on number of classes&#34;&#34;&#34;
    _epochs = epochs if epochs else self.epochs
    _labels = epochs.events[:, -1] if epochs else self.epochs.events[:, -1]
    _, rare, _ = P3.EVENTS_MAPINGS()
    wanted_keys = [
        _epochs.event_id[key]
        for key in _epochs.event_id
        if int(key.split(&#39;/&#39;)[-1]) in rare
    ]
    rare_stims = np.array([_epochs.events[key] for key in wanted_keys])
    rare_stims = rare_stims[:, -1]
    labels = np.where(np.isin(_labels, rare_stims), 1, 2)
    return labels</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.run_sliding_"><code class="name flex">
<span>def <span class="ident">run_sliding_</span></span>(<span>self) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Runs inside a seperate process using multiprocessing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_sliding_(self) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Runs inside a seperate process using multiprocessing&#34;&#34;&#34;
    from mne.decoding.search_light import SlidingEstimator
    from mne.decoding.transformer import Vectorizer
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import StratifiedKFold
    from mne.decoding.base import cross_val_multiscore

    clf_svm = make_pipeline(Vectorizer(), StandardScaler(),
                            svm.SVC(kernel=&#39;linear&#39;, C=1))
    timeDecode = SlidingEstimator(clf_svm, scoring=&#39;roc_auc&#39;, n_jobs=3)
    epochs = self.epochs.load_data()
    labels = self.labels_transform()
    scores = cross_val_multiscore(timeDecode,
                                  epochs.get_data(),
                                  labels,
                                  cv=StratifiedKFold(5, True, 114),
                                  n_jobs=6)
    return (epochs.times, scores)</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.EEGDecoder.run_svm_"><code class="name flex">
<span>def <span class="ident">run_svm_</span></span>(<span>self) ‑> Tuple[object, object]</span>
</code></dt>
<dd>
<div class="desc"><p>Runs inside a seperate process using multiprocessing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_svm_(self) -&gt; Tuple[object, object]:
    &#34;&#34;&#34;Runs inside a seperate process using multiprocessing&#34;&#34;&#34;
    from mne.decoding.transformer import Vectorizer
    from sklearn.preprocessing import StandardScaler
    from sklearn import svm
    from sklearn.model_selection import GridSearchCV, StratifiedKFold
    data, labels = self.get_train(channels=[&#39;Cz&#39;, &#39;CPz&#39;])
    clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(),
                                svm.SVC(random_state=42))
    parameters = {
        &#39;svc__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;sigmoid&#39;],
        &#39;svc__C&#39;: [0.1, 1, 10]
    }
    gs_cv_svm = GridSearchCV(clf_svm_pip,
                             parameters,
                             scoring=&#39;accuracy&#39;,
                             cv=StratifiedKFold(n_splits=5),
                             return_train_score=True)
    gs_cv_svm.fit(data, labels)
    logging.info(&#39;Best Parameters: {}&#39;.format(gs_cv_svm.best_params_))
    logging.info(&#39;Best Score: {}&#39;.format(gs_cv_svm.best_score_))
    return gs_cv_svm.best_score_, gs_cv_svm.best_params_</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.FeatureTransformer"><code class="flex name class">
<span>class <span class="ident">FeatureTransformer</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base Transformer</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class FeatureTransformer(ABC):
    &#34;&#34;&#34;Base Transformer&#34;&#34;&#34;

    @abstractmethod
    def transform() -&gt; np.ndarray:
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="src.decoding_analysis.MNECSPTransformer" href="#src.decoding_analysis.MNECSPTransformer">MNECSPTransformer</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.FeatureTransformer.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def transform() -&gt; np.ndarray:
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.LDADecoder"><code class="flex name class">
<span>class <span class="ident">LDADecoder</span></span>
</code></dt>
<dd>
<div class="desc"><p>Simple sklearn LDA decoder</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class LDADecoder(Classifier):
    &#34;&#34;&#34;Simple sklearn LDA decoder&#34;&#34;&#34;
    lda: LinearDiscriminantAnalysis = field(
        init=False, default_factory=LinearDiscriminantAnalysis)

    def fit(self, data: np.ndarray, labels: np.ndarray) -&gt; None:
        data = data.reshape(data.shape[0], -1)
        self.lda.fit(data, labels)

    def predict(self, data: np.ndarray, labels: np.ndarray) -&gt; float:
        score = self.lda.score(data, labels)
        logging.info(&#34;Score {}&#34;.format(score))
        return score</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.decoding_analysis.Classifier" href="#src.decoding_analysis.Classifier">Classifier</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.decoding_analysis.LDADecoder.lda"><code class="name">var <span class="ident">lda</span> : sklearn.discriminant_analysis.LinearDiscriminantAnalysis</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.LDADecoder.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, data: numpy.ndarray, labels: numpy.ndarray) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, data: np.ndarray, labels: np.ndarray) -&gt; None:
    data = data.reshape(data.shape[0], -1)
    self.lda.fit(data, labels)</code></pre>
</details>
</dd>
<dt id="src.decoding_analysis.LDADecoder.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, data: numpy.ndarray, labels: numpy.ndarray) ‑> float</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, data: np.ndarray, labels: np.ndarray) -&gt; float:
    score = self.lda.score(data, labels)
    logging.info(&#34;Score {}&#34;.format(score))
    return score</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.MNECSPTransformer"><code class="flex name class">
<span>class <span class="ident">MNECSPTransformer</span></span>
<span>(</span><span>n_components: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Simple CSP built on top of MNE</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class MNECSPTransformer(FeatureTransformer):
    &#34;&#34;&#34;Simple CSP built on top of MNE&#34;&#34;&#34;
    n_components: int

    def transform(self, data: np.ndarray, labels: np.ndarray) -&gt; np.ndarray:
        csp = mne.decoding.CSP(self.n_components)
        csp.fit_transform(data, labels)
        return csp.transform(data)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.decoding_analysis.FeatureTransformer" href="#src.decoding_analysis.FeatureTransformer">FeatureTransformer</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.decoding_analysis.MNECSPTransformer.n_components"><code class="name">var <span class="ident">n_components</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.MNECSPTransformer.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, data: numpy.ndarray, labels: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, data: np.ndarray, labels: np.ndarray) -&gt; np.ndarray:
    csp = mne.decoding.CSP(self.n_components)
    csp.fit_transform(data, labels)
    return csp.transform(data)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.decoding_analysis.P3"><code class="flex name class">
<span>class <span class="ident">P3</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class P3:

    @abstractmethod
    def EVENTS_MAPINGS() -&gt; Tuple[dict, list[int], list[int]]:
        &#34;&#34;&#34;Returns events mapping for the P3 task&#34;&#34;&#34;
        blocks = np.array(
            [list(range(10 * x + 1, 10 * x + 6)) for x in range(1, 6)])
        rare = np.array([x + i for i, x in enumerate(range(11, 56, 10))
                        ]).tolist()
        freq = np.setdiff1d(blocks.flatten(), rare).tolist()

        stimlus = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;]

        evts_stim = [
            &#39;stimulus/&#39; + stimlus[i] + &#39;/&#39; + str(alph)
            for i, x in enumerate(blocks)
            for alph in x
        ]
        evts_id = dict((i + 3, evts_stim[i]) for i in range(0, len(evts_stim)))
        evts_id[1] = &#39;response/201&#39;
        evts_id[2] = &#39;response/202&#39;
        return evts_id, rare, freq</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="src.decoding_analysis.P3.EVENTS_MAPINGS"><code class="name flex">
<span>def <span class="ident">EVENTS_MAPINGS</span></span>(<span>) ‑> Tuple[dict, list[int], list[int]]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns events mapping for the P3 task</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def EVENTS_MAPINGS() -&gt; Tuple[dict, list[int], list[int]]:
    &#34;&#34;&#34;Returns events mapping for the P3 task&#34;&#34;&#34;
    blocks = np.array(
        [list(range(10 * x + 1, 10 * x + 6)) for x in range(1, 6)])
    rare = np.array([x + i for i, x in enumerate(range(11, 56, 10))
                    ]).tolist()
    freq = np.setdiff1d(blocks.flatten(), rare).tolist()

    stimlus = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;]

    evts_stim = [
        &#39;stimulus/&#39; + stimlus[i] + &#39;/&#39; + str(alph)
        for i, x in enumerate(blocks)
        for alph in x
    ]
    evts_id = dict((i + 3, evts_stim[i]) for i in range(0, len(evts_stim)))
    evts_id[1] = &#39;response/201&#39;
    evts_id[2] = &#39;response/202&#39;
    return evts_id, rare, freq</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src" href="index.html">src</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.decoding_analysis.CVPipleline" href="#src.decoding_analysis.CVPipleline">CVPipleline</a></code></h4>
<ul class="two-column">
<li><code><a title="src.decoding_analysis.CVPipleline.cv_pip" href="#src.decoding_analysis.CVPipleline.cv_pip">cv_pip</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.evaluate" href="#src.decoding_analysis.CVPipleline.evaluate">evaluate</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.fit" href="#src.decoding_analysis.CVPipleline.fit">fit</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.predict" href="#src.decoding_analysis.CVPipleline.predict">predict</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.test_data" href="#src.decoding_analysis.CVPipleline.test_data">test_data</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.test_labels" href="#src.decoding_analysis.CVPipleline.test_labels">test_labels</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.train_data" href="#src.decoding_analysis.CVPipleline.train_data">train_data</a></code></li>
<li><code><a title="src.decoding_analysis.CVPipleline.train_labels" href="#src.decoding_analysis.CVPipleline.train_labels">train_labels</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.Classifier" href="#src.decoding_analysis.Classifier">Classifier</a></code></h4>
<ul class="">
<li><code><a title="src.decoding_analysis.Classifier.fit" href="#src.decoding_analysis.Classifier.fit">fit</a></code></li>
<li><code><a title="src.decoding_analysis.Classifier.predict" href="#src.decoding_analysis.Classifier.predict">predict</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.CrossTimePipelineDecoder" href="#src.decoding_analysis.CrossTimePipelineDecoder">CrossTimePipelineDecoder</a></code></h4>
<ul class="two-column">
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.X" href="#src.decoding_analysis.CrossTimePipelineDecoder.X">X</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.epochs" href="#src.decoding_analysis.CrossTimePipelineDecoder.epochs">epochs</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.fit" href="#src.decoding_analysis.CrossTimePipelineDecoder.fit">fit</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.pipeline" href="#src.decoding_analysis.CrossTimePipelineDecoder.pipeline">pipeline</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.predict" href="#src.decoding_analysis.CrossTimePipelineDecoder.predict">predict</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.t_scores" href="#src.decoding_analysis.CrossTimePipelineDecoder.t_scores">t_scores</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.timeVec" href="#src.decoding_analysis.CrossTimePipelineDecoder.timeVec">timeVec</a></code></li>
<li><code><a title="src.decoding_analysis.CrossTimePipelineDecoder.y" href="#src.decoding_analysis.CrossTimePipelineDecoder.y">y</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.EEGDecoder" href="#src.decoding_analysis.EEGDecoder">EEGDecoder</a></code></h4>
<ul class="">
<li><code><a title="src.decoding_analysis.EEGDecoder.baseline" href="#src.decoding_analysis.EEGDecoder.baseline">baseline</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.condition" href="#src.decoding_analysis.EEGDecoder.condition">condition</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.decoding_times" href="#src.decoding_analysis.EEGDecoder.decoding_times">decoding_times</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.epoch_times" href="#src.decoding_analysis.EEGDecoder.epoch_times">epoch_times</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.epochs" href="#src.decoding_analysis.EEGDecoder.epochs">epochs</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.equalize_events" href="#src.decoding_analysis.EEGDecoder.equalize_events">equalize_events</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.equalize_ids" href="#src.decoding_analysis.EEGDecoder.equalize_ids">equalize_ids</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.feature_transform" href="#src.decoding_analysis.EEGDecoder.feature_transform">feature_transform</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.get_all_stim" href="#src.decoding_analysis.EEGDecoder.get_all_stim">get_all_stim</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.get_train" href="#src.decoding_analysis.EEGDecoder.get_train">get_train</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.labels_transform" href="#src.decoding_analysis.EEGDecoder.labels_transform">labels_transform</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.raw" href="#src.decoding_analysis.EEGDecoder.raw">raw</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.reject" href="#src.decoding_analysis.EEGDecoder.reject">reject</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.reject_by_annotation" href="#src.decoding_analysis.EEGDecoder.reject_by_annotation">reject_by_annotation</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.run_sliding_" href="#src.decoding_analysis.EEGDecoder.run_sliding_">run_sliding_</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.run_svm_" href="#src.decoding_analysis.EEGDecoder.run_svm_">run_svm_</a></code></li>
<li><code><a title="src.decoding_analysis.EEGDecoder.score" href="#src.decoding_analysis.EEGDecoder.score">score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.FeatureTransformer" href="#src.decoding_analysis.FeatureTransformer">FeatureTransformer</a></code></h4>
<ul class="">
<li><code><a title="src.decoding_analysis.FeatureTransformer.transform" href="#src.decoding_analysis.FeatureTransformer.transform">transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.LDADecoder" href="#src.decoding_analysis.LDADecoder">LDADecoder</a></code></h4>
<ul class="">
<li><code><a title="src.decoding_analysis.LDADecoder.fit" href="#src.decoding_analysis.LDADecoder.fit">fit</a></code></li>
<li><code><a title="src.decoding_analysis.LDADecoder.lda" href="#src.decoding_analysis.LDADecoder.lda">lda</a></code></li>
<li><code><a title="src.decoding_analysis.LDADecoder.predict" href="#src.decoding_analysis.LDADecoder.predict">predict</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.MNECSPTransformer" href="#src.decoding_analysis.MNECSPTransformer">MNECSPTransformer</a></code></h4>
<ul class="">
<li><code><a title="src.decoding_analysis.MNECSPTransformer.n_components" href="#src.decoding_analysis.MNECSPTransformer.n_components">n_components</a></code></li>
<li><code><a title="src.decoding_analysis.MNECSPTransformer.transform" href="#src.decoding_analysis.MNECSPTransformer.transform">transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.decoding_analysis.P3" href="#src.decoding_analysis.P3">P3</a></code></h4>
<ul class="">
<li><code><a title="src.decoding_analysis.P3.EVENTS_MAPINGS" href="#src.decoding_analysis.P3.EVENTS_MAPINGS">EVENTS_MAPINGS</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>