{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('eeg-pipeline': conda)"
  },
  "interpreter": {
   "hash": "173a92a0e93819f22c18d3a068a863ecb9e0b58fa84e48d0a92f0143a680fbf1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "sys.path.append(\"src\") # add the source dir"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "%matplotlib qt\r\n",
    "import mne\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os\r\n",
    "from src.pipeline import Pipeline\r\n",
    "from mne_bids import BIDSPath"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate three random subjects for cleaning and preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import random\r\n",
    "random.seed(1334)\r\n",
    "subjects = [random.randrange(1, 40, 1) for i in range(3)]\r\n",
    "print(\"We will be doing cleaning and processing for subjects {}\".format(subjects))\r\n",
    "bids_root = os.path.join('data', 'P3')\r\n",
    "bids_paths = [ BIDSPath(subject=str(sub).zfill(3), session='P3', task='P3',\r\n",
    "                        datatype='eeg', suffix='eeg', root=bids_root) for sub in subjects]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We will be doing cleaning and processing for subjects [30, 5, 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data for above subjects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "pipelines = [ Pipeline(path).load_data() for path in bids_paths]\r\n",
    "raw_30, raw_5, raw_2 = [pipeline.raw for pipeline in pipelines]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Loading Data\n",
      "INFO:root:Loading Data\n",
      "INFO:root:Loading Data\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Displaying general Information about the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "n_time_samps = raw_30.n_times\r\n",
    "time_secs = raw_30.times\r\n",
    "ch_names = raw_30.ch_names\r\n",
    "n_chan = len(ch_names)\r\n",
    "print('the raw data for subject {} has {} time samples and {} channels.'\r\n",
    "      ''.format(pipelines[0].subject, n_time_samps, n_chan))\r\n",
    "print('The last time sample is at {} seconds.'.format(time_secs[-1]))\r\n",
    "print('The first few channel names are {}....'.format(', '.join(ch_names[:5])))\r\n",
    "print('sample rate:', raw_30.info['sfreq'], 'Hz')\r\n",
    "print('%s channels x %s samples' % (len(raw_30), len(raw_30.times)))\r\n",
    "print(\"The channel names are {}\".format(ch_names))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the raw data for subject 030 has 393216 time samples and 33 channels.\n",
      "The last time sample is at 383.9990234375 seconds.\n",
      "The first few channel names are FP1, F3, F7, FC3, C3....\n",
      "sample rate: 1024.0 Hz\n",
      "393216 channels x 393216 samples\n",
      "The channel names are ['FP1', 'F3', 'F7', 'FC3', 'C3', 'C5', 'P3', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Oz', 'Pz', 'CPz', 'FP2', 'Fz', 'F4', 'F8', 'FC4', 'FCz', 'Cz', 'C4', 'C6', 'P4', 'P8', 'P10', 'PO8', 'PO4', 'O2', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting the EEG data for Pz channel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "eeg_channel_indices = mne.pick_channels(raw_30.ch_names, ['Cz'])\r\n",
    "start_stop_seconds = np.array([10, 50])\r\n",
    "start_sample, stop_sample = raw_30.time_as_index(start_stop_seconds) #(start_stop_seconds * sfreq).astype(int)\r\n",
    "eeg_data, times = raw_30[eeg_channel_indices, start_sample:stop_sample]\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "sns.lineplot(times, eeg_data.T.reshape(-1));"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Displaying Montage settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "montage_dir = os.path.join(os.path.dirname(mne.__file__),\r\n",
    "                           'channels', 'data', 'montages')\r\n",
    "print('\\nBUILT-IN MONTAGE FILES')\r\n",
    "print('======================')\r\n",
    "print(sorted(os.listdir(montage_dir)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "BUILT-IN MONTAGE FILES\n",
      "======================\n",
      "['EGI_256.csd', 'GSN-HydroCel-128.sfp', 'GSN-HydroCel-129.sfp', 'GSN-HydroCel-256.sfp', 'GSN-HydroCel-257.sfp', 'GSN-HydroCel-32.sfp', 'GSN-HydroCel-64_1.0.sfp', 'GSN-HydroCel-65_1.0.sfp', 'artinis-brite23.elc', 'artinis-octamon.elc', 'biosemi128.txt', 'biosemi16.txt', 'biosemi160.txt', 'biosemi256.txt', 'biosemi32.txt', 'biosemi64.txt', 'easycap-M1.txt', 'easycap-M10.txt', 'mgh60.elc', 'mgh70.elc', 'standard_1005.elc', 'standard_1020.elc', 'standard_alphabetic.elc', 'standard_postfixed.elc', 'standard_prefixed.elc', 'standard_primed.elc']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for pipeline in pipelines: pipeline.set_montage() \r\n",
    "fig = plt.figure()\r\n",
    "ax2d = fig.add_subplot(121)\r\n",
    "ax3d = fig.add_subplot(122, projection='3d')\r\n",
    "raw_30.plot_sensors(ch_type='eeg', axes=ax2d, show_names=False); #showing names makes it clumsy\r\n",
    "raw_30.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d');\r\n",
    "ax3d.view_init(azim=70, elev=15);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Standard 1020 montage and EOG channels are set\n",
      "INFO:root:Standard 1020 montage and EOG channels are set\n",
      "INFO:root:Standard 1020 montage and EOG channels are set\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding bad channels and segments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Since, deciding filter setting will be same for all three subjects, we will discuss the need by taking into consideration only one subject, we can remove slow drifts and power line noises from our data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some artifacts are restricted to certain frequencies and can therefore be fixed by filtering. Fow-frequency drifts in raw data can usually be spotted by plotting a fairly long span of data with the plot() method, though it is helpful to disable channel-wise DC shift correction to make slow drifts more readily visible. Here we plot 60 seconds, showing all the channels:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "raw_30.plot(duration=70, proj=False, remove_dc=False);\r\n",
    "# raw_2.plot(duration=70, proj=False, remove_dc=False);\r\n",
    "# raw_5.plot(duration=70, proj=False, remove_dc=False);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![filtering](images/filtering.jpg)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### There seems to be very small drifts in the data, and half-period of this slow drift appears to last around 5 seconds, so a full period would be less than 10 seconds. $( < \\frac{1}{10}Hz )$, To exclude those components, we would want a highpass filter which is higher or equal to $ \\frac{1}{10}Hz $, i.e $( \\frac{1}{5}Hz )$ or  $ ( \\frac{1}{10}Hz )$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Power line noise is an environmental artifact that manifests as persistent oscillations centered around the AC power line frequency"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "raw_30.plot_psd(fmax=250, average=True);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![power line](images/power_line.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### It appears that we have a line noise artifact at around 60Hz. To remove this we will use the low-pass filter at 50HZ. Frequency-domain construction is good when an arbitrary response is desired, but generally less clean (due to sampling issues) than a windowed approach for more straightforward filter applications. Since our filters (low-pass, high-pass, band-pass, band-stop) are fairly simple and we require precise control of all frequency regions, we will primarily use and explore windowed FIR design. Furthermore we will use `firwin` and not `firwin2` because  `firwin` uses a time-domain design technique that generally gives improved attenuation using fewer samples than `firwin2`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "raw_30.filter(l_freq=None, h_freq=50, fir_design='firwin')\r\n",
    "raw_2.filter(l_freq=None, h_freq=50, fir_design='firwin')\r\n",
    "raw_5.filter(l_freq=None, h_freq=50, fir_design='firwin')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<RawEEGLAB | sub-005_ses-P3_task-P3_eeg.fdt, 33 x 391168 (382.0 s), ~98.5 MB, data loaded>"
      ],
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>33 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 30 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>HEOG_left, HEOG_right, VEOG_lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1024.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>50.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-005_ses-P3_task-P3_eeg.fdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:06:21 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finding Eye blinks artifacts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "raw_30"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<RawEEGLAB | sub-030_ses-P3_task-P3_eeg.fdt, 33 x 393216 (384.0 s), ~99.0 MB, data loaded>"
      ],
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>33 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 30 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>HEOG_left, HEOG_right, VEOG_lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1024.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>50.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-030_ses-P3_task-P3_eeg.fdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:06:23 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We will use the `find_eog_events` to find eye blinks events and We’ll start the annotations 250 ms before the blink and end them 250 ms after it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def set_eye_blink_annotations(raw: mne.io.Raw):\r\n",
    "    eog_events = mne.preprocessing.find_eog_events(raw)\r\n",
    "    onsets = eog_events[:, 0] / raw.info['sfreq'] - 0.25\r\n",
    "    durations = [0.5] * len(eog_events)\r\n",
    "    descriptions = ['bad blink'] * len(eog_events)\r\n",
    "    blink_annot = mne.Annotations(onsets, durations, descriptions, orig_time=raw.info['meas_date'])\r\n",
    "    raw.set_annotations(raw.annotations + blink_annot)\r\n",
    "    return eog_events"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "eog_events_30 = set_eye_blink_annotations(raw_30)\r\n",
    "eog_events_2 = set_eye_blink_annotations(raw_2)\r\n",
    "eog_events_5 = set_eye_blink_annotations(raw_5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "eeg_picks = mne.pick_types(raw_30.info, eeg=True)\r\n",
    "raw_30.plot(events=eog_events_30, order=eeg_picks);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Below is the bad blinks artifacts for subject 30 found using mne"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![bad blinks](images/bad_blinks_30.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "eeg_picks = mne.pick_types(raw_2.info, eeg=True)\r\n",
    "raw_2.plot(events=eog_events_2, order=eeg_picks);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Though it appears that it is not very reliable? For example, in the figure below the blink annotation should have been at location 323 seconds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![bad blinks](images/bad_blinks_2.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "eeg_picks = mne.pick_types(raw_5.info, eeg=True)\r\n",
    "raw_5.plot(events=eog_events_5, order=eeg_picks);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![bad blinks](images/bad_blinks_5.svg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Looks like subject 5 has too many blink events\r\n",
    "\r\n",
    "### Going through the raw data using plot it seems like it is giving the correct result, anyhow we will try to perform ICA and see if it removes the artifact. ICA gives feature space decomposition into independent components, and the artifacts contribution is typically localised to small number of components."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Since, our EEG recording has the EOG channels, they can be used in ICA to automatically select the corresponding artifact components from the decomposition."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ICA Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "ica = mne.preprocessing.ICA(n_components=15, method=\"fastica\", random_state=1881)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We will avoid fitting ICA on environmental artifacts which would dominate the variance and decomposition by rejecting them using the voltage cretaria, we would also not want to fit ICA to a bad channel, we can do this by using `mne.picks` but since in our subjects, there are no bad channels, so we won't use it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "reject = dict(eeg=250e-6)  # 200 µV\r\n",
    "ica.fit(raw_30, decim=3, reject=reject, verbose=False) # rouding upto 3 for fast calculations"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ICA | raw data decomposition, fit (fastica): 4098 samples, 15 components, channels used: \"eeg\">"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "ica.plot_components();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Often it is hard to decide on which ICA components to exclude, Therefore we can use `create_eog_epochs` to create the eog epochs and find the `eog_indices` via correlation, but running the code below for subject 5, 30 throws error because according to mne subject 5 is full if eye blinks. So we can't calculate the eye blinks indices because there is too less data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# eog_epochs = mne.preprocessing.create_eog_epochs(raw_30, reject=reject)\r\n",
    "# eog_indices, scores = ica.find_bads_eog(eog_epochs)\r\n",
    "# ica.plot_scores(scores, exclude=eog_indices);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from time import time\r\n",
    "def run_ica(method, fit_params=None):\r\n",
    "    ica = mne.preprocessing.ICA(n_components=20, method=method, random_state=35)\r\n",
    "    ica.fit(raw_30)\r\n",
    "    title = ('ICA decomposition using %s'%(method))\r\n",
    "    ica.plot_components(title=title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "run_ica('fastica')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "run_ica('picard')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "run_ica('infomax')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "raw.plot_psd(average=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18504/946305023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_psd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EPOCHING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = mne.Epochs(raw, events, event_id, tmin=-0.1, tmax=1,\r\n",
    "                    baseline=(None, 0), preload=True)\r\n",
    "print(epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(epochs.events[:3])\r\n",
    "print(epochs.event_id)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(epochs[1:5])\r\n",
    "print(epochs['stimulus/11'])\r\n",
    "print(epochs['stimulus/21'])\r\n",
    "print(epochs['stimulus/31'])\r\n",
    "print(epochs['response'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs.plot_drop_log();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# epochs.plot(block=True, events=events);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs.plot_image(12, cmap='interactive', sigma=1., vmin=-400, vmax=400);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stim_events = dict((k, event_id[k]) for k in event_id.keys() if \"stimulus\" in k)\r\n",
    "epochs = mne.Epochs(raw, events, stim_events, tmin=-0.2, tmax=0.8, picks=['Pz'])\r\n",
    "\r\n",
    "\r\n",
    "# Average epochs for faces and car\r\n",
    "rare_stim = set(range(11, 55+1, 11))\r\n",
    "freq_stim = set(range(11, 55+1)) - set(range(11, 55+1, 11))\r\n",
    "\r\n",
    "evoked_a = epochs[[\"stimulus/{}\".format(f) for f in rare_stim]].average()\r\n",
    "evoked_b = epochs[[\"stimulus/{}\".format(f) for f in freq_stim]].average()\r\n",
    "\r\n",
    "# Plot evokeds\r\n",
    "mne.viz.plot_compare_evokeds({\"Target A\": evoked_a, \"Target B\": evoked_b}, show=False, title=\"ERPs before ICA\", combine=\"mean\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rare_stim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}